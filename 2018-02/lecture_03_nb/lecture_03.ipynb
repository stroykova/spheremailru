{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/header.png\">\n",
    "\n",
    "# Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "\n",
    "## Лекция 3. Классификация текстов и Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## План занятия\n",
    "* Обработка текстов\n",
    "* Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Нужно отметиться на лекции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data Mining vs Text Mining\n",
    "\n",
    "Data Mining:   \n",
    "* извлечение *неочевидной* информации\n",
    "\n",
    "Text Mining:  \n",
    "* извлечение *очевидной* информации\n",
    "\n",
    "Трудности  \n",
    "* Огромные объемы\n",
    "* Отстутсвие структуры\n",
    "\t    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Задачи Text Mining\n",
    "* Суммаризация текста  \n",
    "агрегация новостей\n",
    "* Классификация и кластеризация документов  \n",
    "категоризация, антиспам, sentiment analysis, opinion mining\n",
    "* Извлечение метаданных  \n",
    "определение языка, автора, тегирование\n",
    "* Выделение сущностей  \n",
    "места, люди, компании, почтовые адреса\n",
    "\n",
    "\n",
    "* автоматический перевод\n",
    "* чат-бот\n",
    "* поиск точных ответов на вопросы в тексте"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Этапы (простой) обработки текста\n",
    "\n",
    "<img src=\"images/textm.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "## Декодирование\n",
    "\n",
    "\n",
    "**Def.**  \n",
    "перевод последовательности байт в последовательность символов\n",
    "\n",
    "* Распаковка  \n",
    "*plain/.zip/.gz/...*\n",
    "* Кодировка  \n",
    "*ASCII/utf-8/Windows-1251/...*\n",
    "* Формат  \n",
    "*csv/xml/json/doc...*\n",
    "\n",
    "Кроме того: что такое документ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Разбиение на токены\n",
    "**Def.**  \n",
    "разбиение последовательности символов на части (токены), возможно, исключая из рассмотрения некоторые символы  \n",
    "Наивный подход: разделить строку пробелами и выкинуть знаки препинания  \n",
    "\n",
    "\n",
    "*Трисия любила Нью-Йорк, поскольку любовь к Нью-Йорку могла положительно повлиять на ее карьеру.*  \n",
    "\n",
    "\n",
    "**Проблемы:**  \n",
    "* n.anokhin@corp.mail.ru, 127.0.0.1\n",
    "* С++, C#\n",
    "* York University vs New York University\n",
    "* Зависимость от языка (“Lebensversicherungsgesellschaftsangestellter”, “l’amour”)\n",
    "Альтернатива: n-граммы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Разбиение на токены\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\папик\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Трисия\n",
      "любила\n",
      "Нью\n",
      "-\n",
      "Йорк\n",
      ",\n",
      "поскольку\n",
      "любовь\n",
      "к\n",
      "Нью\n",
      "-\n",
      "Йорку\n",
      "могла\n",
      "положительно\n",
      "повлиять\n",
      "на\n",
      "ее\n",
      "карьеру\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer('\\w+|[^\\w\\s]+')\n",
    "s = u'Трисия любила Нью-Йорк, поскольку любовь к Нью-Йорку могла положительно повлиять на ее карьеру.'\n",
    "for t in tokenizer.tokenize(s): \n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Стоп-слова\n",
    "**Def.**  \n",
    "Наиболее частые слова в языке, не содержащие никакой информации о содержании текста\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в во не что он на я с со как а то все она так его но да ты\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(' '.join(stopwords.words('russian')[1:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Проблема: “To be or not to be\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Нормализация\n",
    "**Def.**  \n",
    "Приведение токенов к единому виду для того, чтобы избавиться от поверхностной разницы в написании  \n",
    "\n",
    "Подходы  \n",
    "* сформулировать набор правил, по которым преобразуется токен  \n",
    "Нью-Йорк → нью-йорк → ньюйорк → ньюиорк\n",
    "* явно хранить связи между токенами (WordNet – Princeton)  \n",
    "машина → автомобиль, Windows 6→ window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "нью-йорк\n"
     ]
    }
   ],
   "source": [
    "s = u'Нью-Йорк'\n",
    "s1 = s.lower()\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ньюйорк\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "s2 = re.sub(r\"\\W\", \"\", s1, flags=re.U)\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ньюиорк\n"
     ]
    }
   ],
   "source": [
    "s3 = re.sub(r\"й\", u\"и\", s2, flags=re.U)\n",
    "print(s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Стемминг и Лемматизация\n",
    "**Def.**  \n",
    "Приведение грамматических форм слова и однокоренных слов к единой основе (lemma):\n",
    "* Stemming – с помощью простых эвристических правил\n",
    "  * Porter (Cambridge – 1980)\n",
    "        5 этапов, на каждом применяется набор правил, таких как\n",
    "            sses → ss (caresses → caress)\n",
    "            ies → i (ponies → poni)\n",
    "\n",
    "  * Lovins (1968)\n",
    "  * Paice (1990)\n",
    "  * другие\n",
    "* Lemmatization – с использованием словарей и морфологического анализа\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Стемминг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token\n",
      "stem\n",
      "авиац\n",
      "национальн\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import PorterStemmer\n",
    "s = PorterStemmer()\n",
    "print(s.stem('Tokenization'))\n",
    "print(s.stem('stemming'))\n",
    "\n",
    "from nltk.stem.snowball import RussianStemmer\n",
    "r = RussianStemmer()\n",
    "print(r.stem(u'Авиация'))\n",
    "print(r.stem(u'национальный'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Наблюдение**  \n",
    "для сложных языков лучше подходит лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "print(morph.parse(u'думающему')[0].normal_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Heaps' law\n",
    "\n",
    "$$\n",
    "M = k T^\\beta, \\;M \\text{ -- размер словаря}, \\; T \\text{ -- количество слов в корпусе}\n",
    "$$\n",
    "$$\n",
    "30 \\leq k \\leq 100, \\; b \\approx 0.5\n",
    "$$\n",
    "\n",
    "<img src=\"images/dim.png\">\n",
    "<img src=\"images/heaps.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Представление документов\n",
    "**Boolean Model.** Присутствие или отсутствие слова в документе  \n",
    "**Bag of Words.** Порядок токенов не важен  \n",
    "\n",
    "*Погода была ужасная, принцесса была прекрасная.\n",
    "Или все было наоборот?*\n",
    "\n",
    "Координаты\n",
    "* Мультиномиальные: количество токенов в документе\n",
    "* Числовые: взвешенное количество токенов в документе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Zipf's law\n",
    "\n",
    "$t_1, \\ldots, t_N$ - токены, отранжированные по убыванию частоты\n",
    "   \t\n",
    "$f_1, \\dots, f_N$ - соответствующие частоты\n",
    "\n",
    "**Закон Ципфа**\n",
    "\t$$\n",
    "\tf_i = \\frac{c}{i^k}\n",
    "\t$$\t\n",
    "\t\n",
    "\tЧто еще? Посещаемость сайтов, количество друзей, население городов...\n",
    "<img src=\"images/zipf.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## TF-IDF\n",
    "\n",
    "Количество вхождений слова $t$ в документе $d$\n",
    "$$\n",
    "TF_{t,d} = term\\!\\!-\\!\\!frequency(t, d)\n",
    "$$\n",
    "Количество документов из $N$ возможных, где встречается $t$\n",
    "$$\n",
    "DF_t = document\\!\\!-\\!\\!fequency(t)\n",
    "$$\n",
    "$$\n",
    "IDF_t = inverse\\!\\!-\\!\\!document\\!\\!-\\!\\!frequency(t) = \\log \\frac{N}{DF_t}\n",
    "$$\n",
    "TF-IDF\n",
    "$$\n",
    "TF\\!\\!-\\!\\!IDF_{t,d} = TF_{t,d} \\times IDF_t\n",
    "$$\n",
    "\n",
    "Оценивает важность слова в контексте документа, являющегося частью корпуса\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Перерыв\n",
    "## Опрос"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Байесовский классификатор\n",
    "\n",
    "Дано\n",
    "\n",
    "$\\mathbf{x} \\in X$ - описание документа $d$ из коллекции $D$  \n",
    "$C_k \\in C, \\; k = 1,\\ldots,K$ - целевая переменная\n",
    "\n",
    "Теорема Байеса\n",
    "$$\n",
    "P(C_k \\mid \\mathbf{x}) = \\frac{p(\\mathbf{x} \\mid C_k) p(C_k)}{p(\\mathbf{x})} \\propto p(\\mathbf{x} \\mid C_k) p(C_k)\n",
    "$$\n",
    "\n",
    "Принцип Maximum A-Posteriori\n",
    "$$\n",
    "C_{MAP} = \\arg \\max_k p(C_k | \\mathbf{x})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Байесовский классификатор — широкий класс алгоритмов классификации, основанный на принципе максимума апостериорной вероятности.  \n",
    "Для классифицируемого объекта вычисляются функции правдоподобия каждого из классов, по ним вычисляются апостериорные вероятности классов.  \n",
    "Объект относится к тому классу, для которого апостериорная вероятность максимальна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "## Naive Bayes\n",
    "\n",
    "$x_j$ - слово на $j$-м месте в документе $\\mathbf{x}$,  \n",
    "$w^i \\in V$ - слово из словаря $V$\n",
    "\n",
    "\n",
    "Предположения\n",
    "* conditional independence - слова внутри документа независимы\n",
    "$$\n",
    "p(x_i=w^s, x_j=w^r | C_k) = p(x_i=w^s | C_k) p(x_j=w^r | C_k)\n",
    "$$\n",
    "* postional independence - результат не зависит от позиции слова в документе\n",
    "$$\n",
    "P(x_i=w^s | C_k) = P(x_j=w^s | C_k) = P(x = w^s | C_k)\n",
    "$$\n",
    "\n",
    "Получаем\n",
    "$$\n",
    "p(\\mathbf{x} | C_k) = p(x_1=w^{s_1}, \\ldots, x_{|\\mathbf{x}|}=w^{s_{|\\mathbf{x}|}} | C_k) = \\prod_{i=1}^{|\\mathbf{x}|} p(x = w^{s_i} | C_k)\n",
    "$$\n",
    "\n",
    "**Почему NB хорошо работает?**  \n",
    "Корректная оценка дает правильное предсказание, но правильное предсказание *не требует* корректной оценки\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Варианты NB\n",
    "\n",
    "MAP\n",
    "$$\n",
    "C_{MAP} = \\arg \\max_k p(C_k) \\prod_{i=1}^{|\\mathbf{x}|} p(x = w^{s_i} | C_k)  = \n",
    "$$\n",
    "$$\n",
    "= \\arg \\max_k \\left[ \\log p(C_k) + \\sum_{i=1}^{|\\mathbf{x}|} \\log p(x = w^{s_i} | C_k) \\right]\n",
    "$$\n",
    "Априорные вероятности\n",
    "$$\n",
    "p(C_k) = N_{C_k}/{N}\n",
    "$$\n",
    "Likelihood $p(x = w^{s_i} | C_k)$\n",
    "* BernoulliNB $p(x = w^{s_i} | C_k) = D_{w^{s_i}, C_k} / D_{C_k}$, $D$ - кол-во документов\n",
    "* MultinomialNB $p(x = w^{s_i} | C_k) = T_{w^{s_i}, C_k} / T_{C_k}$, $T$ - кол-во токенов\n",
    "* GaussianNB $p(x = w^{s_i} | C_k) = \\mathcal{N}(\\mu_k, \\sigma_k^2)$, параметры из MLE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Обучение NB\n",
    "\n",
    "```\n",
    "function nb_train(D,C):\n",
    "\tV = dictionary of tokens\n",
    "\tN = number of documents\n",
    "\tfor Ck in C: # iterate over all classes\n",
    "\t\tN_Ck = number of documents in class Ck\n",
    "\t\tp(Ck) = N_Ck / N # Class prior\n",
    "\t\tD_Ck = Documents in class Ck\t\t\n",
    "\t\tfor w_i in V:\t\t\t\n",
    "\t\t\t# multinomial, bernoulli, gaussian\n",
    "\t\t\tp(w_i|Ck) = count_likelihood(...)\n",
    "\treturn V, p(Ck), p(w_i|Ck)\n",
    "```\n",
    "\n",
    "Алгоритмическая сложность: $O(|D| \\langle |\\mathbf{x}| \\rangle + |C||V|)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Применение MultinomialNB\n",
    "\n",
    "\n",
    "```\n",
    "function nb_apply(d, C, V, p(Ck), p(w_i|Ck)):\n",
    "\tx = tokenize(d) # somehow\t\n",
    "\tfor Ck in C: # iterate over all classes\n",
    "\t\tscore(Ck|x) = log p(Ck) # use class prior\n",
    "\t\t# use likelihoods\n",
    "\t\tfor i in 1..|x|:\t\t\n",
    "\t\t\tscore(Ck|x) += log p(x_i|Ck)\n",
    "\treturn arg max score(Ck|x)\n",
    "```\n",
    "\n",
    "Алгоритмическая сложность: $O(|C||\\mathbf{x}|)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Задача\n",
    "\n",
    "|d | Текст | Класс |\n",
    "|--|--|--|\n",
    "|1 | котики такие мокрые | мимими |\n",
    "|2 | пушистые котики няшки | мимими |\n",
    "|3 | морские котики  | не мимими |\n",
    "|4 | мокрые морские свинки | не мимими |\n",
    "|5 | котики мокрые | ???|\n",
    "\n",
    "С помощью алгоритма MultinomialNB вычислить $p(\\text{мимими} | d_5)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Сглаживание\n",
    "\n",
    "Проблема: $p(свинки|мимими) = 0$\n",
    "\n",
    "Решение:\n",
    "\n",
    "$$ p(x=w_{s_i}|C_k) = \\frac{ T_{w^{s_i}, C_k} + \\alpha }{ T_{C_k} + \\alpha|V|} $$\n",
    "\n",
    "\n",
    "если $\\alpha \\geq 0$ - сглаживание Лапласа, если $0 \\leq \\alpha \\leq 1$ - Лидстоуна\n",
    "\n",
    "**Упражнение**  \n",
    "С учетом сглаживания вычислить $$p(пушистые|не мимими), p(пушистые|мимими)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Итоги\n",
    "\n",
    "**+** (Удивительно) неплохо работает  \n",
    "**+** Стабилен при смещении выборки  \n",
    "**+** Оптимальный по производительности  \n",
    "\n",
    "**-** Наивные предположения  \n",
    "**-** Требует отбора признаков  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Вопросы\n",
    "## Пожалуйста, оставьте отзыв о лекции"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
